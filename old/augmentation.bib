@Article{Shorten2019,
author={Shorten, Connor
and Khoshgoftaar, Taghi M.},
title={A survey on Image Data Augmentation for Deep Learning},
journal={Journal of Big Data},
year={2019},
volume={6},
number={1},
pages={60},
abstract={Deep convolutional neural networks have performed remarkably well on many Computer Vision tasks. However, these networks are heavily reliant on big data to avoid overfitting. Overfitting refers to the phenomenon when a network learns a function with very high variance such as to perfectly model the training data. Unfortunately, many application domains do not have access to big data, such as medical image analysis. This survey focuses on Data Augmentation, a data-space solution to the problem of limited data. Data Augmentation encompasses a suite of techniques that enhance the size and quality of training datasets such that better Deep Learning models can be built using them. The image augmentation algorithms discussed in this survey include geometric transformations, color space augmentations, kernel filters, mixing images, random erasing, feature space augmentation, adversarial training, generative adversarial networks, neural style transfer, and meta-learning. The application of augmentation methods based on GANs are heavily covered in this survey. In addition to augmentation techniques, this paper will briefly discuss other characteristics of Data Augmentation such as test-time augmentation, resolution impact, final dataset size, and curriculum learning. This survey will present existing methods for Data Augmentation, promising developments, and meta-level decisions for implementing Data Augmentation. Readers will understand how Data Augmentation can improve the performance of their models and expand limited datasets to take advantage of the capabilities of big data.},
issn={2196-1115},
doi={10.1186/s40537-019-0197-0},
url={https://doi.org/10.1186/s40537-019-0197-0}
}
@misc{chatfield2014return,
    title={Return of the Devil in the Details: Delving Deep into Convolutional Nets},
    author={Ken Chatfield and Karen Simonyan and Andrea Vedaldi and Andrew Zisserman},
    year={2014},
    eprint={1405.3531},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}
@InProceedings{10.1007/978-3-642-14058-7_55,
author="Jurio, Aranzazu
and Pagola, Miguel
and Galar, Mikel
and Lopez-Molina, Carlos
and Paternain, Daniel",
editor="H{\"u}llermeier, Eyke
and Kruse, Rudolf
and Hoffmann, Frank",
title="A Comparison Study of Different Color Spaces in Clustering Based Image Segmentation",
booktitle="Information Processing and Management of Uncertainty in Knowledge-Based Systems. Applications",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="532--541",
abstract="In this work we carry out a comparison study between different color spaces in clustering-based image segmentation. We use two similar clustering algorithms, one based on the entropy and the other on the ignorance. The study involves four color spaces and, in all cases, each pixel is represented by the values of the color channels in that space. Our purpose is to identify the best color representation, if there is any, when using this kind of clustering algorithms.",
isbn="978-3-642-14058-7"
}
@misc{summers2018improved,
    title={Improved Mixed-Example Data Augmentation},
    author={Cecilia Summers and Michael J. Dinneen},
    year={2018},
    eprint={1805.11272},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}
@misc{zhong2017random,
    title={Random Erasing Data Augmentation},
    author={Zhun Zhong and Liang Zheng and Guoliang Kang and Shaozi Li and Yi Yang},
    year={2017},
    eprint={1708.04896},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}
@article{Takahashi_2019,
   title={Data Augmentation using Random Image Cropping and Patching for Deep CNNs},
   ISSN={1558-2205},
   url={http://dx.doi.org/10.1109/TCSVT.2019.2935128},
   DOI={10.1109/tcsvt.2019.2935128},
   journal={IEEE Transactions on Circuits and Systems for Video Technology},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Takahashi, Ryo and Matsubara, Takashi and Uehara, Kuniaki},
   year={2019},
   pages={1–1}
}
@inproceedings{10.1117/12.2293971,
author = {Ali Madani and Mehdi Moradi and Alexandros Karargyris and Tanveer Syeda-Mahmood},
title = {{Chest x-ray generation and data augmentation for cardiovascular abnormality classification}},
volume = {10574},
booktitle = {Medical Imaging 2018: Image Processing},
editor = {Elsa D. Angelini and Bennett A. Landman},
organization = {International Society for Optics and Photonics},
publisher = {SPIE},
pages = {415 -- 420},
keywords = {Generative adversarial networks , Convolutional networks, data augmentation },
year = {2018},
doi = {10.1117/12.2293971},
URL = {https://doi.org/10.1117/12.2293971}
}
@article{GOODFELLOW201559,
title = "Challenges in representation learning: A report on three machine learning contests",
journal = "Neural Networks",
volume = "64",
pages = "59 - 63",
year = "2015",
note = "Special Issue on “Deep Learning of Representations”",
issn = "0893-6080",
doi = "https://doi.org/10.1016/j.neunet.2014.09.005",
url = "http://www.sciencedirect.com/science/article/pii/S0893608014002159",
author = "Ian J. Goodfellow and Dumitru Erhan and Pierre Luc Carrier and Aaron Courville and Mehdi Mirza and Ben Hamner and Will Cukierski and Yichuan Tang and David Thaler and Dong-Hyun Lee and Yingbo Zhou and Chetan Ramaiah and Fangxiang Feng and Ruifan Li and Xiaojie Wang and Dimitris Athanasakis and John Shawe-Taylor and Maxim Milakov and John Park and Radu Ionescu and Marius Popescu and Cristian Grozea and James Bergstra and Jingjing Xie and Lukasz Romaszko and Bing Xu and Zhang Chuang and Yoshua Bengio",
keywords = "Representation learning, Competition, Dataset",
abstract = "The ICML 2013 Workshop on Challenges in Representation Learning11http://deeplearning.net/icml2013-workshop-competition. focused on three challenges: the black box learning challenge, the facial expression recognition challenge, and the multimodal learning challenge. We describe the datasets created for these challenges and summarize the results of the competitions. We provide suggestions for organizers of future challenges and some comments on what kind of knowledge can be gained from machine learning competitions."
}